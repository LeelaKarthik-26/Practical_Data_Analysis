{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPp3ATOc2BOTcL7f4K1q+He",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeelaKarthik-26/IT7103/blob/main/PDA_Assignmet4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/PDA_Assignmet4.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF0skrIagyqM",
        "outputId": "d8eaa803-b674-43b5-8de6-77952a9d7cf7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/PDA_Assignmet4.ipynb to html\n",
            "[NbConvertApp] Writing 588849 bytes to /content/PDA_Assignmet4.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IT7103 â€“ Assignment 4"
      ],
      "metadata": {
        "id": "ceBISb1MaVY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this assignment, you will be introduced to one application of data analytics in healthcare informatics. Specifically, we will work with predicting breast cancer cases.\n",
        "The data consists of 699 recorded cases, of which about 34.5% are malignant. The data has 11 columns:\n",
        "1.\tCase number\n",
        "2.\tClump Thickness\n",
        "3.\tUniformity of Cell Size\n",
        "4.\tUniformity of Cell Shape\n",
        "5.\tMarginal Adhesion\n",
        "6.\tSingle Epithelial Cell Size\n",
        "7.\tBare Nuclei\n",
        "8.\tBland Chromatin\n",
        "9.\tNormal Nucleoli\n",
        "10.\tMitoses\n",
        "11.\tClass: 0 for benign, 1 for malignant\n",
        "Column 11 is our target. This data is very clean, and all columns are already numeric, so no preprocessing is required besides train/test split. However, be careful with which columns you include in the input data.\n",
        "Please fit Linear and Kernel (both RBF and Linear) Support Vector Machine on the breast cancer data. Please note that you need to finetune both models. You can choose the range of values for each hyper-parameter.\n",
        "Please report both the cross-validation training accuracy and the testing accuracy.\n",
        "Please submit the Jupyter notebook file with all the codes and outputs, and its HTML version.\n"
      ],
      "metadata": {
        "id": "o5aQoLHKaOwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/breast-cancer.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTiDO3oZY0ZA",
        "outputId": "0be5ad8f-3dc2-4cbb-f922-4036f5efad72"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7Ha-lxyUYVck"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = data.drop(['ID', 'Class'], axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "ALbhyg3cZqYz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train and evaluate SVM models\n",
        "def train_and_evaluate_svm(kernel, param_grid):\n",
        "    svm = SVC(kernel=kernel)\n",
        "    grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    train_accuracy = best_model.score(X_train_scaled, y_train)\n",
        "    test_accuracy = best_model.score(X_test_scaled, y_test)\n",
        "\n",
        "    print(f\"{kernel.capitalize()} SVM Results:\")\n",
        "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "    print(f\"Cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
        "    print(f\"Training accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Testing accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "2OF7lUTMY6uL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear SVM\n",
        "linear_param_grid = {'C': [0.1, 1, 10, 100]}\n",
        "train_and_evaluate_svm('linear', linear_param_grid)\n",
        "\n",
        "# RBF Kernel SVM\n",
        "rbf_param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.01, 0.1, 1, 10]}\n",
        "train_and_evaluate_svm('rbf', rbf_param_grid)\n",
        "\n",
        "# Linear Kernel SVM\n",
        "linear_kernel_param_grid = {'C': [0.1, 1, 10, 100]}\n",
        "train_and_evaluate_svm('linear', linear_kernel_param_grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKFycuS3ZrdF",
        "outputId": "5c7bcefb-6a92-4b50-8d6f-7365b2006637"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear SVM Results:\n",
            "Best parameters: {'C': 0.1}\n",
            "Cross-validation accuracy: 0.9624\n",
            "Training accuracy: 0.9714\n",
            "Testing accuracy: 0.9643\n",
            "Rbf SVM Results:\n",
            "Best parameters: {'C': 1, 'gamma': 0.01}\n",
            "Cross-validation accuracy: 0.9660\n",
            "Training accuracy: 0.9660\n",
            "Testing accuracy: 0.9714\n",
            "Linear SVM Results:\n",
            "Best parameters: {'C': 0.1}\n",
            "Cross-validation accuracy: 0.9624\n",
            "Training accuracy: 0.9714\n",
            "Testing accuracy: 0.9643\n"
          ]
        }
      ]
    }
  ]
}